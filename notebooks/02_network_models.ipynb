{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Network Models\n",
    "#### Author: [Erika Fille Legara](https://erikalegara.site)\n",
    "\n",
    "\n",
    "[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/eflegara/Network-Science-Lectures/blob/master/LICENSE.md) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eflegara/Network-Science-Lectures/blob/master/CN%20Models.ipynb)\n",
    "\n",
    "For context, this notebook is accompanied by a lecture session under the Network Science course under [AIM's MSc in Data Science program](https://aim.edu/programs/degree-programs/master-science-data-science).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant references:\n",
    "1. Erdős, P.; Rényi, A. (1959). \"On Random Graphs. I\". _Publicationes Mathematicae_. **6**: 290–297.\n",
    "2. Watts, D. J.; Strogatz, S. H. (1998). \"Collective dynamics of 'small-world' networks\". _Nature_. **393** (6684): 440–442. \n",
    "3.  Barabási, A.-L.; Albert, R. ( 1999). \"Emergence of scaling in random networks\". _Science_. **286** (5439): 509–512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import binom\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erdős-Renyi Model (Random Network Model)\n",
    "\n",
    "In a random network model, it is assumed that the links (or edges) in the network are formed, well, randomly. The randomness here refers to the existence of relationships between entities in a network. For example, if we are considering a friendship network and model the said network using one of the more famous random network models, the ER model, we are assuming that friendship connections are formed by some random chance $p$. We refer to this as the $G(n,p)$ model. We will discuss another variant below.   \n",
    "\n",
    "Random networks have the following properties.\n",
    "\n",
    "1. Degree distribution obeys a Binomial distribution and approximates a Poisson distribution for large $n$.\n",
    "2. The network has **low clustering coefficient**.\n",
    "3. The network has **short characteristic path length**.\n",
    "\n",
    "Constructing a random graph is fairly straightforward. Again, one can start by listing all the possible edges that could exist in a graph with $n$ nodes; i.e., for a graph with $n$ nodes, there is a total of $L=n(n-1)/2$ possible links or edges. \n",
    "\n",
    "In a random network, each of these potential $L$ links has a probability $p$ of being present in the network and $q=1-p$ otherwise. It is easy to show that in a randomly generated network, the expected number of links $\\bar{L}$ is $\\frac{n(n-1)p}{2}$. \n",
    "\n",
    "This can also be verified algorithmically as shown in the next cell. \n",
    "\n",
    "As an example, let $N=100$ nodes and $p=0.001$. Mathematically, $\\bar{L} = 4.95$. Let's check if the simulation results agree after running a total of 5000 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_experiments = 5000\n",
    "n = 100\n",
    "p = 0.001\n",
    "all_pairs = int(n*(n-1)/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.985"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sums = []\n",
    "for i in range(total_experiments):\n",
    "    total_edges = 0\n",
    "    for pair in range(all_pairs):\n",
    "        if np.random.random() < p:\n",
    "            total_edges = total_edges + 1\n",
    "    sums.append(total_edges)\n",
    "np.mean(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, that's quite close to the expected number of links obtained analytically.\n",
    "\n",
    "As mentioned, $G(n,p)$ is just one model for constructing a random network; another way is by initially defining the total number of nodes $n$ and total number of links $m$ then randomly generating graphs that have $n$ nodes and $m$ links, $G(n,m)$, then randomly choosing one of these generated graphs. \n",
    "\n",
    "The good news is that we need not explicitly write the code for these two models—although they're straightforward to write—since [networkx](https://networkx.org) actually has these graph generators.\n",
    "\n",
    "```python\n",
    "nx.erdos_renyi_graph(n,p)\n",
    "nx.gnm_random_graph(n,m)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectedness \n",
    "But what really is interesting for Erdős and Renyi about random network models ($G(n,p)$) is when a network becomes connected; that is, the critical probability of connection $p^*$ where a network transitions from a network that's scattered/disconnected to a connected one. A connected network is a network where a path exists between any two pair of nodes in the network. Let's visualize this by iterating through $p$ values generated using the command `np.logspace(-3,0,15)`; the arguments used are arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = []\n",
    "fig = plt.figure(figsize=(20,20));\n",
    "\n",
    "i=0\n",
    "for p in np.logspace(-3,0,9):\n",
    "    ax = fig.add_subplot(3, 3, i+1);\n",
    "    ER = nx.erdos_renyi_graph(n=50,p=p)\n",
    "    pos = nx.fruchterman_reingold_layout(ER)\n",
    "    nc = nx.draw_networkx_nodes(ER, pos=pos, node_size=300, cmap=plt.cm.RdYlBu,\n",
    "                                node_color='black');\n",
    "    nx.draw_networkx_edges(ER, pos=pos, alpha=0.500);\n",
    "    nx.draw_networkx_labels(ER, pos=pos, font_color='white');\n",
    "    plt.title(\"p: \" + str(np.round(p,2)))\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytically, Erdős and Renyi previously showed that the threshold $p^* \\approx (\\ln N)/N$.\n",
    "\n",
    "We can explore this further by using `nx.is_connected(G)` to check whether the generated network is connected or not. \n",
    "\n",
    "As in above, let's build a small graph ($n=50$) and tune $p$ until a network becomes connected. This time, let's print the first $p$ value when the network becomes connected. In addition, let's hack a generalization with multiple experiments. A sample script is written below. In this example, as mentioned, we are using only a small graph ($n=500$), and we are also only performing a small experiment with only 500 iterations; bigger experiments take much longer time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pstar = []\n",
    "n = 100\n",
    "for i in range(1000):\n",
    "    for p in np.logspace(-3,0,25):\n",
    "        if nx.is_connected(nx.erdos_renyi_graph(n=n,p=p)):\n",
    "            pstar.append(p)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05647420929254206, 0.01163755267044887)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pstar), np.std(pstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to ER, for $n=500$, the threshold $p^*$ is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04605170185988092"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(n)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is, of course, an expected difference between the result of the in-silico experiments with that of the theoretical $p^*$, especially since we are only performing a few iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Distribution\n",
    "For a random network, we expect a Binomial distribution of degrees of connectivity; i.e.,\n",
    "\n",
    "\\begin{equation}\n",
    "p(k) = {{n-1} \\choose k} p^k (1-p)^{(n-1)-k}.\n",
    "\\end{equation}\n",
    "\n",
    "${{n-1} \\choose k}$ simply means that we select $k$ nodes from $(n-1)$ possible nodes where a node can be linked to.\n",
    "For large $n$, the distribution approximates a Poissonian distribution.\n",
    "\n",
    "\\begin{equation}\n",
    "p(k) = \\exp ^{-<k>}\\frac{<k>^k}{k!}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "\n",
    "ER = nx.erdos_renyi_graph(n=5000, p=0.01)\n",
    "degrees = [k for node, k in nx.degree(ER)]\n",
    "\n",
    "_, bins, _ = ax.hist(degrees, bins=15, density=True, label=\"data\");\n",
    "bin_middles = 0.5 * (bins[1:] + bins[:-1]);\n",
    "mu, sigma = scipy.stats.norm.fit(degrees)\n",
    "best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n",
    "\n",
    "ax.plot(bins, best_fit_line, lw=3, label=\"fit\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Coefficient and Path Length\n",
    "\n",
    "Aside from the degree distribution, the two other properties of networks usually computed are the **average clustering coefficient** $C$ and the **characteristic path length** $l$, which is the average shortest path length between all node pairs in the network. \n",
    "\n",
    "For the ER graph we have constructed, the $C$ and $l$ are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Coefficient: 0.009918590876104914\n",
      "Characteristic Path Length: 2.593438607721544\n"
     ]
    }
   ],
   "source": [
    "C = nx.average_clustering(ER)\n",
    "l = nx.average_shortest_path_length(ER)\n",
    "print(\"Clustering Coefficient:\", C)\n",
    "print(\"Characteristic Path Length:\", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For large $n$, computing the shortest path lengths for all pairs can take a while to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree distribution, clustering coefficient, and characteristic path lengths are usually the first metrics investigated when studying real-world networks. They are part of the EDA. And the ER model ($G(n,m)$) or the $G(n,p)$ is a base model for complex networks; we use random network models to compare statistics vs. that of real-world networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have only looked at networks randomly generated algorithmically. How accurate are these models when studying/describing real-world networks? \n",
    "\n",
    "Let's have a look.\n",
    "\n",
    "### C. elegans\n",
    "\n",
    "The first network we have is the neural network of the *C. elegans* nematode \\[1\\]. \n",
    "\n",
    "> Note: If you are running this on Google Colab, the `nx.read_gml()` in the input cell below will result to an error; all other cells that read external files will result to errors since in Google Colab reading files is not straightforward. To fix the issue, download the datasets first from the Github repository and then upload them on your own Google Drive. Then execute the code:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "```\n",
    "\n",
    ">Assuming you upload the data in a directory `MyData` on your drive, you may read the file as:\n",
    "\n",
    "```python\n",
    "data_dir = \"/content/drive/MyDrive/MyData/\"\n",
    "marvel = pd.read_csv(data_dir + \"hero-network.csv\", header=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph from a gml file\n",
    "G = nx.read_gml(\"datasets/celegansneural.gml\", label=\"id\")\n",
    "G = nx.Graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Nodes: 297\n",
      "No. of Links: 2148\n"
     ]
    }
   ],
   "source": [
    "# graph properties\n",
    "print(\"No. of Nodes:\", len(G.nodes()))\n",
    "print(\"No. of Links:\", len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree distribution\n",
    "plt.plot(nx.degree_histogram(G),'.');\n",
    "plt.xlabel(\"Degree\");\n",
    "plt.ylabel(\"Total Nodes\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29236329783219017 2.455318955318955\n"
     ]
    }
   ],
   "source": [
    "# clustering coefficient and the characteristic path length\n",
    "cc = nx.average_clustering(G)\n",
    "l = nx.average_shortest_path_length(G)\n",
    "print(cc, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we can use a random network model for comparison. We can first compare the $C$ and $l$ values; and see if we can use a random network model to reproduce the numbers. To this we can construct a random network using the $G(n,m)$ model where $n$ and $m$ are the number of nodes and number of edges of the real-world network, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04882461240429807 2.425175175175175\n"
     ]
    }
   ],
   "source": [
    "cc_random = nx.average_clustering(nx.gnm_random_graph(len(G.nodes()), len(G.edges()), seed=22))\n",
    "l_random = nx.average_shortest_path_length(nx.gnm_random_graph(len(G.nodes()), len(G.edges()), seed=22))\n",
    "print(cc_random, l_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the $l$ values, we can see that they're within the same magnitude and are approximately the same. On the other hand, the clustering coefficient for the _C. elegans_ network is much higher than that generated by a random model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$C$</th>\n",
       "      <th>$l$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C. elegans NN</th>\n",
       "      <td>0.292363</td>\n",
       "      <td>2.455319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random network</th>\n",
       "      <td>0.048825</td>\n",
       "      <td>2.425175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     $C$       $l$\n",
       "C. elegans NN   0.292363  2.455319\n",
       "Random network  0.048825  2.425175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[cc,l],[cc_random, l_random]], index = [\"C. elegans NN\", \"Random network\"], columns=[\"$C$\", \"$l$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaboration Network (Network Science)\n",
    "Let's have a look at another real-world network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"datasets/netscience.gml\", label=\"id\")\n",
    "G = nx.Graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the graph is not connected, we cannot really compute for the characteristic path length since we will have distances of infinity for some node pairs (i.e., no path exists between them). What we'll do instead is have a look at the biggest subgraph (connected component; giant component) and analyze that.\n",
    "\n",
    "But before that, let's have a look at the histogram first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(nx.degree_histogram(G),'.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The giant component of a network can be obtained by extracting all connected components of the graph and choosing the biggest one in terms of the number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_nodes = max(nx.connected_components(G), key=len)\n",
    "GC = G.subgraph(GC_nodes).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412306142925664 6.041867347935949\n"
     ]
    }
   ],
   "source": [
    "cc = nx.average_clustering(GC)\n",
    "l = nx.average_shortest_path_length(GC)\n",
    "print(cc, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Nodes: 379\n",
      "No. of Links: 914\n"
     ]
    }
   ],
   "source": [
    "# graph properties\n",
    "print(\"No. of Nodes:\", len(GC.nodes()))\n",
    "print(\"No. of Links:\", len(GC.edges()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously a sparse graph where the total number of edges is very much less than the total number of potential links; i.e., $e << L$. Thus, we will only compute for the clustering coefficient since it will be challenging to generate random connected network with the provided $n$ and $m$ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0070337753715062415\n"
     ]
    }
   ],
   "source": [
    "cc_random = nx.average_clustering(nx.gnm_random_graph(len(GC.nodes()), len(GC.edges()), seed=22))\n",
    "# l_random = nx.average_shortest_path_length(nx.gnm_random_graph(len(GC.nodes()), len(GC.edges()), seed=42))\n",
    "print(cc_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$C$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Collaboration network</th>\n",
       "      <td>0.741231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random network</th>\n",
       "      <td>0.007034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            $C$\n",
       "Collaboration network  0.741231\n",
       "Random network         0.007034"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[cc],[cc_random]], index = [\"Collaboration network\", \"Random network\"], columns=[\"$C$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the _C. elegans_ network, we can observe that the clustering coefficient for the collaboration network is much higher than the clustering coefficient of a random network of the same parameters, $n$ and $m$.\n",
    "\n",
    "In fact, a similar trend was discovered by Watts and Strogatz when they studied the same _C. elegans_ network, a network of film actors, and a power grid network: the existence of high clustering coefficient and short path lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small-World Model\n",
    "\n",
    "Indeed, Watts and Strogatz discovered that some real-world networks exhibit certain properties, which are not present in random networks generated using the $G(n,p)$ and $G(n,m)$ models. In particular, the real-world networks they studied have high average clustering coefficients and short characteristic path lengths. \n",
    "\n",
    "\n",
    "Given their observation, they proposed another network model known as the small-world network model (aka Watts-Strogatz model). It's a generative model that reconstructs both the observed high clustering and short characteristic path lengths of many real-world networks. \n",
    "\n",
    "In the Watts-Strogatz model, graph generation begins with a regular network where each node is connected to $k$ other nodes in the network; i.e., all nodes have the same number of connections/neighbors. Then, with some probability $\\rho$, each existing link in the network is rewired.\n",
    " \n",
    "Let's build a Watts-Strogatz network with $n=5000$ nodes, $k=10$ average degree (for each node), and $\\rho=0.15$ reconnection probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS = nx.watts_strogatz_graph(n=5000, k=10, p=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40857525474525475 5.084519463892779\n"
     ]
    }
   ],
   "source": [
    "cc = nx.average_clustering(WS)\n",
    "l = nx.average_shortest_path_length(WS)\n",
    "print(cc, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a random network with the same $n$ total nodes and $e$ total edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00186614212412974 3.9459583116623325\n"
     ]
    }
   ],
   "source": [
    "cc_random = nx.average_clustering(nx.gnm_random_graph(len(WS.nodes()), len(WS.edges()), seed=22))\n",
    "l_random = nx.average_shortest_path_length(nx.gnm_random_graph(len(WS.nodes()), len(WS.edges()), seed=22))\n",
    "print(cc_random, l_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$C$</th>\n",
       "      <th>$l$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WS model</th>\n",
       "      <td>0.408575</td>\n",
       "      <td>5.084519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER model</th>\n",
       "      <td>0.001866</td>\n",
       "      <td>3.945958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               $C$       $l$\n",
       "WS model  0.408575  5.084519\n",
       "ER model  0.001866  3.945958"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[cc,l],[cc_random, l_random]], index = [\"WS model\", \"ER model\"], columns=[\"$C$\", \"$l$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that the $l$ values for both ER and WS are comparable for the same $n$ and $e$; however, more clustering is observed in the WS model (given the high $C$) than the ER model.\n",
    "\n",
    "Let's take again the *C. elegans* example and compare the statistics against those generated from both WS and ER models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph from a gml file\n",
    "G = nx.read_gml(\"datasets/celegansneural.gml\", label=\"id\")\n",
    "G = nx.Graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_network_comparisons(G, rho, network_name):\n",
    "    avg_k = int(np.mean([deg for node, deg in G.degree()]))\n",
    "    n = len(G.nodes())\n",
    "    e = len(G.edges())\n",
    "    \n",
    "    ws_model = nx.watts_strogatz_graph(n=n, k=avg_k, p=rho)\n",
    "    er_model = nx.gnm_random_graph(n=n, m=e)\n",
    "\n",
    "    cc = nx.average_clustering(G)\n",
    "    try:\n",
    "        l = nx.average_shortest_path_length(G)\n",
    "    except:\n",
    "        l = \"disconnected\"\n",
    "    cc_ws = nx.average_clustering(ws_model)\n",
    "    try:\n",
    "        l_ws = nx.average_shortest_path_length(ws_model)\n",
    "    except:\n",
    "        l_ws = \"disconnected\"\n",
    "    cc_er = nx.average_clustering(er_model)\n",
    "    try:\n",
    "        l_er = nx.average_shortest_path_length(er_model)\n",
    "    except:\n",
    "        l_er = \"disconnected\"\n",
    "\n",
    "    df = pd.DataFrame([[cc,l],[cc_ws, l_ws], [cc_er, l_er]], \n",
    "                      index = [network_name, \"WS model\", \"ER model\"],\n",
    "                      columns=[\"$C$\", \"$l$\"])\n",
    "    return ws_model, er_model, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C. Elegans Neural Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$C$</th>\n",
       "      <th>$l$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN</th>\n",
       "      <td>0.292363</td>\n",
       "      <td>2.455319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS model</th>\n",
       "      <td>0.291655</td>\n",
       "      <td>2.647306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER model</th>\n",
       "      <td>0.054893</td>\n",
       "      <td>2.426085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               $C$       $l$\n",
       "NN        0.292363  2.455319\n",
       "WS model  0.291655  2.647306\n",
       "ER model  0.054893  2.426085"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"C. Elegans Neural Network\")\n",
    "ws_model, er_model, df = gen_network_comparisons(G, 0.25, \"NN\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the WS model was able to reconstruct the two characteristics of the *C. elegans* neural network. In contrast with the ER model, which was not able to reproduce the high clustering coefficient of the real-world network. In this respect, we can say that the WS model was able to reconstruct the real-world neural network; again, if we are to base the performance solely on $C$ and $l$. \n",
    "\n",
    "How about the degree distributions? How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(nx.degree_histogram(G), \"ro\", label=\"data\");\n",
    "plt.loglog(nx.degree_histogram(ws_model), \"b^\", label=\"WS model\");\n",
    "plt.loglog(nx.degree_histogram(er_model), \"gs\", label=\"ER model\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts on the patterns?\n",
    "\n",
    "Now let's look at the collaboration network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaboration Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$C$</th>\n",
       "      <th>$l$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Collaboration Network</th>\n",
       "      <td>0.741231</td>\n",
       "      <td>6.041867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS model</th>\n",
       "      <td>0.440193</td>\n",
       "      <td>9.955829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER model</th>\n",
       "      <td>0.017861</td>\n",
       "      <td>3.940012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            $C$       $l$\n",
       "Collaboration Network  0.741231  6.041867\n",
       "WS model               0.440193  9.955829\n",
       "ER model               0.017861  3.940012"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.read_gml(\"datasets/netscience.gml\", label=\"id\")\n",
    "G = nx.Graph(G)\n",
    "GC_nodes = max(nx.connected_components(G), key=len)\n",
    "GC = G.subgraph(GC_nodes).copy()\n",
    "\n",
    "print(\"Collaboration Network\")\n",
    "ws_model, er_model, df = gen_network_comparisons(GC, 0.035, \"Collaboration Network\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any comment on the numbers? What happens when you change the reconnection probability of the WS model?\n",
    "\n",
    "How about the degree distributions? How do they compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(nx.degree_histogram(G), \"ro\", label=\"data\");\n",
    "plt.loglog(nx.degree_histogram(ws_model), \"b^\", label=\"WS model\");\n",
    "plt.loglog(nx.degree_histogram(er_model), \"gs\", label=\"ER model\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts on the numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristic Path Length and Clustering Coefficient\n",
    "\n",
    "Let's have a closer look at both the characteristic path length and the average clustering coefficient of networks generated by the WS model for different values of the rewiring probability $\\rho$. In particular, let's look at the trend when we move from a regular network (WS$_{\\rho=0}$), to a small-world network, to a random one (WS$_{\\rho=1}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.logspace(-3,0,10)\n",
    "l_vals = []\n",
    "c_vals = []\n",
    "for p in pvals:\n",
    "    G = nx.watts_strogatz_graph(n=1000, k=10, p=p, seed=222)\n",
    "    l_vals.append(nx.average_shortest_path_length(G))\n",
    "    c_vals.append(nx.average_clustering(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_vals_normed = [l/l_vals[0] for l in l_vals]\n",
    "c_vals_normed = [c/c_vals[0] for c in c_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(pvals,l_vals_normed,'bs', label = \"char. path length\");\n",
    "plt.semilogx(pvals,c_vals_normed, 'ro', label = \"ave. clust coeff\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barabási-Albert Model \n",
    "\n",
    "In a separate work (from Watts and Strogatz') on complex networks, Réka Albert and  Albert-László Barabási focused on the degree distribution of real-world networks. As you saw in the above examples and comparisons, although the WS model was _somehow_ able to capture the high clustering coefficient and short path length of the real-world networks, it wasn't really able to reconstruct the observed degree distributions. This gap is much more pronounced in large complex networks.\n",
    "\n",
    "Let's take as an example the Enron email network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enron Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.loadtxt(\"datasets/Email-Enron.txt\")\n",
    "G_enron= nx.Graph()\n",
    "G_enron.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(G_enron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_nodes = max(nx.connected_components(G_enron), key=len)\n",
    "GC = G_enron.subgraph(GC_nodes).copy()\n",
    "n = len(GC.nodes())\n",
    "avg_k = int(np.mean([deg for node, deg in GC.degree()]))\n",
    "e = len(GC.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_model = nx.watts_strogatz_graph(n=n, k=avg_k, p=0.09)\n",
    "er_model = nx.gnm_random_graph(n=n, m=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron Email Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clustering Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Email Network</th>\n",
       "      <td>0.509190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS model</th>\n",
       "      <td>0.504798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER model</th>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Clustering Coefficient\n",
       "Email Network                0.509190\n",
       "WS model                     0.504798\n",
       "ER model                     0.000323"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Enron Email Network\")\n",
    "pd.DataFrame([[nx.average_clustering(GC)],\n",
    "              [nx.average_clustering(ws_model)],\n",
    "              [nx.average_clustering(er_model)]], columns=[\"Clustering Coefficient\"], \n",
    "             index = [\"Email Network\", \n",
    "                      \"WS model\", \n",
    "                      \"ER model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy-tail Degree Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the degree distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(nx.degree_histogram(GC),'ro', label=\"data\");\n",
    "plt.loglog(nx.degree_histogram(ws_model),'g^', label=\"WS model\");\n",
    "plt.loglog(nx.degree_histogram(er_model),'bs', label=\"ER model\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distributions generated by both the WS and ER models do not capture the true degree distribution of the real-world network, which is heavy-tailed.\n",
    "\n",
    "To reflect this property of the degree distribution, Barabási and Albert proposed a network model that has two mechanisms: (1) growth and (2) preferential attachment. The idea is we start with a network of very few nodes and then  grow the network by adding nodes one at a time. The added nodes then attach themselves to $m$ existing nodes in the network with a preference for those nodes with higher degrees; i.e., those that have more connections are much more preferred by the new nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_model = nx.barabasi_albert_graph(n=n, m=avg_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(nx.degree_histogram(GC),'ro', label=\"data\");\n",
    "plt.loglog(nx.degree_histogram(ba_model),'g^', label=\"BA model\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that looks like a better approximation of the degree distribution. What can you say about this degree distribution? \n",
    "\n",
    "### Other Statistics\n",
    "How about the average clustering coefficient and the characteristic path length? \n",
    "\n",
    "*In this notebook, I won't be computing the characteristic path lengths for the networks since it takes a while to generate results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron Email Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clustering Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Email Network</th>\n",
       "      <td>0.509190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS model</th>\n",
       "      <td>0.504798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER model</th>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA model</th>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Clustering Coefficient\n",
       "Email Network                0.509190\n",
       "WS model                     0.504798\n",
       "ER model                     0.000323\n",
       "BA model                     0.004101"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Enron Email Network\")\n",
    "pd.DataFrame([[nx.average_clustering(GC)],\n",
    "              [nx.average_clustering(ws_model)],\n",
    "              [nx.average_clustering(er_model)], \n",
    "              [nx.average_clustering(ba_model)]], columns=[\"Clustering Coefficient\"], \n",
    "             index = [\"Email Network\", \"WS model\", \"ER model\", \"BA model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts?\n",
    "Finally, how do you think will the model results change if we also used the [**configuration model**](https://en.wikipedia.org/wiki/Configuration_model)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
